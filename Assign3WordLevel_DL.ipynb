{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Assign3WordLevel_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD7tKRKxY9iz",
        "colab_type": "text"
      },
      "source": [
        "#Translation Using Word Level Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn4zLTKRfYbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "818e419c-eaa8-4521-96d6-c0a44f855f74"
      },
      "source": [
        "%tensorflow_version 1.14\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow import keras\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.data import Dataset\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "print(tf.__version__)\n",
        "import string\n",
        "from string import digits\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slo_js7h_zNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines= pd.read_table('hin.txt', names=['eng','hin','otherdata'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rEBMNaKfYbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = lines[0:50000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfnv_TdOfYbv",
        "colab_type": "code",
        "outputId": "203e0ce5-2150-4fa9-ec0b-0ba1bd919cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lines.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2778, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGsoGyK2fYby",
        "colab_type": "code",
        "outputId": "713df1b4-03bb-4b9b-b619-cc1ef794e564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>hin</th>\n",
              "      <th>otherdata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>He was sentenced to death.</td>\n",
              "      <td>उसे मौत की सज़ा दे दी गई।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2195</th>\n",
              "      <td>Workers must have their hair cut short.</td>\n",
              "      <td>कर्मचारियों को अपने बाल छोटे कटाने होते हैं।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>He has a beard.</td>\n",
              "      <td>उसके पास दाढ़ी है।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>He took advantage of my youth.</td>\n",
              "      <td>उसने मेरे जवान होने का फ़ायदा उठाया।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>Tom isn't able to drive yet.</td>\n",
              "      <td>टॉम अभी गाड़ी नहीं चला सकता।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>He couldn't get the job.</td>\n",
              "      <td>उसको नौकरी नहीं मिल पायी।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1572</th>\n",
              "      <td>Why were you late this morning?</td>\n",
              "      <td>तुम आज सुबह देर से क्यों आए?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1516</th>\n",
              "      <td>I have a bone to pick with you.</td>\n",
              "      <td>मैं तुमसे खुश नहीं हूँ।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>He envied my success.</td>\n",
              "      <td>उसको मेरी कामयाबी से जलन थी।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1898</th>\n",
              "      <td>Learning a foreign language is fun.</td>\n",
              "      <td>विदेषी भाषा सीखना बहुत मज़ेदार होता है।</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          eng  ...                                          otherdata\n",
              "1005               He was sentenced to death.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "2195  Workers must have their hair cut short.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "150                           He has a beard.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1417           He took advantage of my youth.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1290             Tom isn't able to drive yet.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "798                  He couldn't get the job.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "1572          Why were you late this morning?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "1516          I have a bone to pick with you.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "517                     He envied my success.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1898      Learning a foreign language is fun.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5BwAGbyfYb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
        "lines.hin=lines.hin.apply(lambda x: x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSWa4H9afYb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take the length as 50\n",
        "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
        "lines.hin=lines.hin.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myykPQWEfYb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exclude = set(string.punctuation)\n",
        "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines.hin=lines.hin.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF3_c5iRfYb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
        "lines.hin=lines.hin.apply(lambda x: x.translate(remove_digits))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwketyWsfYcB",
        "colab_type": "code",
        "outputId": "6cfca0a1-5bef-4f3c-c7f3-e36883d5d0f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "lines.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>hin</th>\n",
              "      <th>otherdata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow</td>\n",
              "      <td>वाह</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>help</td>\n",
              "      <td>बचाओ</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jump</td>\n",
              "      <td>उछलो</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jump</td>\n",
              "      <td>कूदो</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jump</td>\n",
              "      <td>छलांग</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    eng    hin                                          otherdata\n",
              "0   wow    वाह  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "1  help   बचाओ  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "2  jump   उछलो  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "3  jump   कूदो  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "4  jump  छलांग  CC-BY 2.0 (France) Attribution: tatoeba.org #6..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kABTlAiPfYcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines.hin = lines.hin.apply(lambda x : 'START_ '+ x + ' _END')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NNtRaebfYcH",
        "colab_type": "code",
        "outputId": "c17c837e-d49c-455e-876f-6fe86862c70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "lines.hin.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      START_ वाह _END\n",
              "1     START_ बचाओ _END\n",
              "2     START_ उछलो _END\n",
              "3     START_ कूदो _END\n",
              "4    START_ छलांग _END\n",
              "Name: hin, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsdr5e39fYcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_eng_words=set()\n",
        "for eng in lines.eng:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "    \n",
        "all_hindi_words=set()\n",
        "for hin in lines.hin:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSD3-keefYcO",
        "colab_type": "code",
        "outputId": "2e349b7b-2346-43db-be46-e95345a86c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(all_eng_words), len(all_hindi_words)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2345, 2991)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5gXJkxifYcR",
        "colab_type": "code",
        "outputId": "c1b19243-6676-4539-bf6e-797d14b56596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lenght_list=[]\n",
        "for l in lines.hin:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "np.max(lenght_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuFZ-gAufYcU",
        "colab_type": "code",
        "outputId": "401960c2-7931-4db9-b0a3-38e1d8dbcceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lenght_list=[]\n",
        "for l in lines.eng:\n",
        "    lenght_list.append(len(l.split(' ')))\n",
        "np.max(lenght_list)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnk3sU4mfYcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeCRnlCUfYca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict(\n",
        "    [(word, i) for i, word in enumerate(target_words)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erK665hzfYce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(lines.eng), 23),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(lines.hin), 29),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(lines.hin), 29, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-5IB1INfYcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.hin)):\n",
        "    for t, word in enumerate(input_text.split()):\n",
        "        encoder_input_data[i, t] = input_token_index[word]\n",
        "    for t, word in enumerate(target_text.split()):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t] = target_token_index[word]\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32nkWfLrZLgM",
        "colab_type": "text"
      },
      "source": [
        "###Build keras encoder-decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMkvX3N7fYck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Goj7HEXUfYcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3zXznMdfYcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9a159fe1-5d02-452e-b50d-1cc7feccfff7"
      },
      "source": [
        "#Encoder model\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "en_x=  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
        "encoder = LSTM(50, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(en_x)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EhY8Pg2fYcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2847d377-c778-47b5-bf4f-bd15c51213cd"
      },
      "source": [
        "#Decoder model\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "dex=  Embedding(num_decoder_tokens, embedding_size)\n",
        "\n",
        "final_dex= dex(decoder_inputs)\n",
        "\n",
        "\n",
        "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC_90pN3fYc1",
        "colab_type": "code",
        "outputId": "5e529eed-0950-417d-83f6-a551a29cc363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    234500      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 100)    299100      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 50), (None,  30200       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 50), ( 30200       embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 2991)   152541      lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 746,541\n",
            "Trainable params: 746,541\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFV9PhejfYc-",
        "colab_type": "code",
        "outputId": "719049f5-7d22-445b-a891-083584e90407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17394
        }
      },
      "source": [
        "#Fit the model\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=128,\n",
        "          epochs=500,\n",
        "          validation_split=0.05)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 2639 samples, validate on 139 samples\n",
            "Epoch 1/500\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "2639/2639 [==============================] - 11s 4ms/step - loss: 1.9295 - acc: 0.0321 - val_loss: 3.1524 - val_acc: 0.0345\n",
            "Epoch 2/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 1.6307 - acc: 0.0345 - val_loss: 3.0058 - val_acc: 0.0345\n",
            "Epoch 3/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 1.5500 - acc: 0.0345 - val_loss: 3.0096 - val_acc: 0.0345\n",
            "Epoch 4/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 1.5211 - acc: 0.0345 - val_loss: 3.0187 - val_acc: 0.0345\n",
            "Epoch 5/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 1.4997 - acc: 0.0345 - val_loss: 3.0235 - val_acc: 0.0345\n",
            "Epoch 6/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 1.4794 - acc: 0.0345 - val_loss: 3.0146 - val_acc: 0.0345\n",
            "Epoch 7/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 1.4616 - acc: 0.0345 - val_loss: 3.0055 - val_acc: 0.0345\n",
            "Epoch 8/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.4456 - acc: 0.0345 - val_loss: 3.0196 - val_acc: 0.0345\n",
            "Epoch 9/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 1.4317 - acc: 0.0349 - val_loss: 3.0079 - val_acc: 0.0345\n",
            "Epoch 10/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 1.4172 - acc: 0.0374 - val_loss: 3.0173 - val_acc: 0.0375\n",
            "Epoch 11/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.4038 - acc: 0.0383 - val_loss: 3.0101 - val_acc: 0.0377\n",
            "Epoch 12/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 1.3904 - acc: 0.0385 - val_loss: 3.0150 - val_acc: 0.0397\n",
            "Epoch 13/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.3776 - acc: 0.0393 - val_loss: 3.0124 - val_acc: 0.0387\n",
            "Epoch 14/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 1.3659 - acc: 0.0401 - val_loss: 3.0156 - val_acc: 0.0412\n",
            "Epoch 15/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.3541 - acc: 0.0412 - val_loss: 3.0163 - val_acc: 0.0417\n",
            "Epoch 16/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 1.3427 - acc: 0.0416 - val_loss: 3.0226 - val_acc: 0.0414\n",
            "Epoch 17/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 1.3315 - acc: 0.0427 - val_loss: 3.0247 - val_acc: 0.0404\n",
            "Epoch 18/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 1.3208 - acc: 0.0435 - val_loss: 3.0343 - val_acc: 0.0407\n",
            "Epoch 19/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 1.3102 - acc: 0.0445 - val_loss: 3.0336 - val_acc: 0.0407\n",
            "Epoch 20/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 1.3009 - acc: 0.0458 - val_loss: 3.0381 - val_acc: 0.0402\n",
            "Epoch 21/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 1.2908 - acc: 0.0468 - val_loss: 3.0377 - val_acc: 0.0427\n",
            "Epoch 22/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 1.2821 - acc: 0.0478 - val_loss: 3.0481 - val_acc: 0.0409\n",
            "Epoch 23/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 1.2732 - acc: 0.0485 - val_loss: 3.0459 - val_acc: 0.0414\n",
            "Epoch 24/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 1.2639 - acc: 0.0495 - val_loss: 3.0463 - val_acc: 0.0439\n",
            "Epoch 25/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 1.2552 - acc: 0.0500 - val_loss: 3.0487 - val_acc: 0.0442\n",
            "Epoch 26/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 1.2478 - acc: 0.0507 - val_loss: 3.0447 - val_acc: 0.0454\n",
            "Epoch 27/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 1.2385 - acc: 0.0512 - val_loss: 3.0393 - val_acc: 0.0447\n",
            "Epoch 28/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 1.2299 - acc: 0.0518 - val_loss: 3.0402 - val_acc: 0.0466\n",
            "Epoch 29/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.2221 - acc: 0.0522 - val_loss: 3.0390 - val_acc: 0.0459\n",
            "Epoch 30/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 1.2134 - acc: 0.0530 - val_loss: 3.0348 - val_acc: 0.0476\n",
            "Epoch 31/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.2058 - acc: 0.0532 - val_loss: 3.0327 - val_acc: 0.0474\n",
            "Epoch 32/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 1.1980 - acc: 0.0539 - val_loss: 3.0333 - val_acc: 0.0494\n",
            "Epoch 33/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 1.1903 - acc: 0.0544 - val_loss: 3.0260 - val_acc: 0.0496\n",
            "Epoch 34/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.1816 - acc: 0.0549 - val_loss: 3.0239 - val_acc: 0.0486\n",
            "Epoch 35/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 1.1757 - acc: 0.0553 - val_loss: 3.0264 - val_acc: 0.0494\n",
            "Epoch 36/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 1.1664 - acc: 0.0560 - val_loss: 3.0409 - val_acc: 0.0496\n",
            "Epoch 37/500\n",
            "2639/2639 [==============================] - 2s 671us/step - loss: 1.1600 - acc: 0.0561 - val_loss: 3.0169 - val_acc: 0.0516\n",
            "Epoch 38/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 1.1520 - acc: 0.0571 - val_loss: 3.0219 - val_acc: 0.0511\n",
            "Epoch 39/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 1.1449 - acc: 0.0576 - val_loss: 3.0280 - val_acc: 0.0518\n",
            "Epoch 40/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 1.1370 - acc: 0.0581 - val_loss: 3.0271 - val_acc: 0.0536\n",
            "Epoch 41/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 1.1303 - acc: 0.0593 - val_loss: 3.0244 - val_acc: 0.0518\n",
            "Epoch 42/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 1.1230 - acc: 0.0600 - val_loss: 3.0150 - val_acc: 0.0526\n",
            "Epoch 43/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 1.1164 - acc: 0.0605 - val_loss: 3.0352 - val_acc: 0.0528\n",
            "Epoch 44/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 1.1091 - acc: 0.0613 - val_loss: 3.0310 - val_acc: 0.0536\n",
            "Epoch 45/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 1.1016 - acc: 0.0619 - val_loss: 3.0374 - val_acc: 0.0516\n",
            "Epoch 46/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 1.0951 - acc: 0.0629 - val_loss: 3.0263 - val_acc: 0.0533\n",
            "Epoch 47/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 1.0884 - acc: 0.0635 - val_loss: 3.0192 - val_acc: 0.0531\n",
            "Epoch 48/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 1.0812 - acc: 0.0645 - val_loss: 3.0165 - val_acc: 0.0536\n",
            "Epoch 49/500\n",
            "2639/2639 [==============================] - 2s 671us/step - loss: 1.0737 - acc: 0.0651 - val_loss: 3.0324 - val_acc: 0.0538\n",
            "Epoch 50/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 1.0681 - acc: 0.0660 - val_loss: 3.0271 - val_acc: 0.0558\n",
            "Epoch 51/500\n",
            "2639/2639 [==============================] - 2s 704us/step - loss: 1.0605 - acc: 0.0670 - val_loss: 3.0384 - val_acc: 0.0558\n",
            "Epoch 52/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 1.0536 - acc: 0.0676 - val_loss: 3.0495 - val_acc: 0.0566\n",
            "Epoch 53/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 1.0473 - acc: 0.0682 - val_loss: 3.0326 - val_acc: 0.0573\n",
            "Epoch 54/500\n",
            "2639/2639 [==============================] - 2s 695us/step - loss: 1.0414 - acc: 0.0694 - val_loss: 3.0246 - val_acc: 0.0585\n",
            "Epoch 55/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 1.0337 - acc: 0.0705 - val_loss: 3.0231 - val_acc: 0.0576\n",
            "Epoch 56/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 1.0282 - acc: 0.0711 - val_loss: 3.0512 - val_acc: 0.0571\n",
            "Epoch 57/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 1.0211 - acc: 0.0719 - val_loss: 3.0431 - val_acc: 0.0590\n",
            "Epoch 58/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 1.0152 - acc: 0.0725 - val_loss: 3.0285 - val_acc: 0.0581\n",
            "Epoch 59/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 1.0094 - acc: 0.0733 - val_loss: 3.0345 - val_acc: 0.0578\n",
            "Epoch 60/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 1.0018 - acc: 0.0745 - val_loss: 3.0327 - val_acc: 0.0588\n",
            "Epoch 61/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.9956 - acc: 0.0753 - val_loss: 3.0400 - val_acc: 0.0585\n",
            "Epoch 62/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.9899 - acc: 0.0755 - val_loss: 3.0519 - val_acc: 0.0588\n",
            "Epoch 63/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.9838 - acc: 0.0764 - val_loss: 3.0657 - val_acc: 0.0590\n",
            "Epoch 64/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.9780 - acc: 0.0768 - val_loss: 3.0497 - val_acc: 0.0600\n",
            "Epoch 65/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.9722 - acc: 0.0779 - val_loss: 3.0585 - val_acc: 0.0588\n",
            "Epoch 66/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.9668 - acc: 0.0786 - val_loss: 3.0389 - val_acc: 0.0585\n",
            "Epoch 67/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.9598 - acc: 0.0790 - val_loss: 3.0590 - val_acc: 0.0588\n",
            "Epoch 68/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.9542 - acc: 0.0800 - val_loss: 3.0549 - val_acc: 0.0595\n",
            "Epoch 69/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.9483 - acc: 0.0802 - val_loss: 3.0535 - val_acc: 0.0578\n",
            "Epoch 70/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.9431 - acc: 0.0815 - val_loss: 3.0585 - val_acc: 0.0585\n",
            "Epoch 71/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.9370 - acc: 0.0821 - val_loss: 3.0753 - val_acc: 0.0588\n",
            "Epoch 72/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.9309 - acc: 0.0829 - val_loss: 3.0487 - val_acc: 0.0588\n",
            "Epoch 73/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.9259 - acc: 0.0833 - val_loss: 3.0776 - val_acc: 0.0590\n",
            "Epoch 74/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.9197 - acc: 0.0845 - val_loss: 3.0742 - val_acc: 0.0585\n",
            "Epoch 75/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.9146 - acc: 0.0853 - val_loss: 3.0848 - val_acc: 0.0595\n",
            "Epoch 76/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.9092 - acc: 0.0856 - val_loss: 3.0709 - val_acc: 0.0593\n",
            "Epoch 77/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.9041 - acc: 0.0864 - val_loss: 3.0813 - val_acc: 0.0595\n",
            "Epoch 78/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.8969 - acc: 0.0872 - val_loss: 3.0930 - val_acc: 0.0576\n",
            "Epoch 79/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.8928 - acc: 0.0881 - val_loss: 3.0761 - val_acc: 0.0581\n",
            "Epoch 80/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.8868 - acc: 0.0884 - val_loss: 3.0905 - val_acc: 0.0583\n",
            "Epoch 81/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.8824 - acc: 0.0889 - val_loss: 3.0946 - val_acc: 0.0590\n",
            "Epoch 82/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.8762 - acc: 0.0901 - val_loss: 3.0967 - val_acc: 0.0588\n",
            "Epoch 83/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.8712 - acc: 0.0909 - val_loss: 3.0890 - val_acc: 0.0605\n",
            "Epoch 84/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.8658 - acc: 0.0915 - val_loss: 3.1026 - val_acc: 0.0598\n",
            "Epoch 85/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.8607 - acc: 0.0921 - val_loss: 3.1096 - val_acc: 0.0605\n",
            "Epoch 86/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.8548 - acc: 0.0930 - val_loss: 3.0993 - val_acc: 0.0598\n",
            "Epoch 87/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.8505 - acc: 0.0935 - val_loss: 3.1033 - val_acc: 0.0605\n",
            "Epoch 88/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.8434 - acc: 0.0947 - val_loss: 3.1149 - val_acc: 0.0603\n",
            "Epoch 89/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.8401 - acc: 0.0951 - val_loss: 3.1042 - val_acc: 0.0605\n",
            "Epoch 90/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.8335 - acc: 0.0957 - val_loss: 3.1210 - val_acc: 0.0620\n",
            "Epoch 91/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.8286 - acc: 0.0962 - val_loss: 3.1092 - val_acc: 0.0595\n",
            "Epoch 92/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.8235 - acc: 0.0972 - val_loss: 3.1216 - val_acc: 0.0600\n",
            "Epoch 93/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.8191 - acc: 0.0978 - val_loss: 3.1196 - val_acc: 0.0598\n",
            "Epoch 94/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.8135 - acc: 0.0983 - val_loss: 3.1339 - val_acc: 0.0613\n",
            "Epoch 95/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.8093 - acc: 0.0990 - val_loss: 3.1272 - val_acc: 0.0608\n",
            "Epoch 96/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.8028 - acc: 0.1001 - val_loss: 3.1379 - val_acc: 0.0613\n",
            "Epoch 97/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.7984 - acc: 0.1008 - val_loss: 3.1322 - val_acc: 0.0628\n",
            "Epoch 98/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.7932 - acc: 0.1012 - val_loss: 3.1347 - val_acc: 0.0625\n",
            "Epoch 99/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.7875 - acc: 0.1023 - val_loss: 3.1450 - val_acc: 0.0620\n",
            "Epoch 100/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.7837 - acc: 0.1026 - val_loss: 3.1418 - val_acc: 0.0600\n",
            "Epoch 101/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.7783 - acc: 0.1039 - val_loss: 3.1662 - val_acc: 0.0610\n",
            "Epoch 102/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.7737 - acc: 0.1041 - val_loss: 3.1503 - val_acc: 0.0608\n",
            "Epoch 103/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.7684 - acc: 0.1047 - val_loss: 3.1523 - val_acc: 0.0620\n",
            "Epoch 104/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.7632 - acc: 0.1059 - val_loss: 3.1566 - val_acc: 0.0625\n",
            "Epoch 105/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.7595 - acc: 0.1062 - val_loss: 3.1719 - val_acc: 0.0625\n",
            "Epoch 106/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.7536 - acc: 0.1074 - val_loss: 3.1721 - val_acc: 0.0635\n",
            "Epoch 107/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.7486 - acc: 0.1083 - val_loss: 3.1866 - val_acc: 0.0623\n",
            "Epoch 108/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.7439 - acc: 0.1088 - val_loss: 3.1941 - val_acc: 0.0595\n",
            "Epoch 109/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.7391 - acc: 0.1097 - val_loss: 3.1764 - val_acc: 0.0615\n",
            "Epoch 110/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.7346 - acc: 0.1108 - val_loss: 3.1887 - val_acc: 0.0625\n",
            "Epoch 111/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.7300 - acc: 0.1112 - val_loss: 3.1727 - val_acc: 0.0623\n",
            "Epoch 112/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.7250 - acc: 0.1123 - val_loss: 3.1891 - val_acc: 0.0628\n",
            "Epoch 113/500\n",
            "2639/2639 [==============================] - 2s 692us/step - loss: 0.7204 - acc: 0.1128 - val_loss: 3.1954 - val_acc: 0.0625\n",
            "Epoch 114/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.7150 - acc: 0.1140 - val_loss: 3.1913 - val_acc: 0.0628\n",
            "Epoch 115/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.7120 - acc: 0.1143 - val_loss: 3.1967 - val_acc: 0.0635\n",
            "Epoch 116/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.7064 - acc: 0.1152 - val_loss: 3.1999 - val_acc: 0.0620\n",
            "Epoch 117/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.7010 - acc: 0.1161 - val_loss: 3.2018 - val_acc: 0.0625\n",
            "Epoch 118/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.6974 - acc: 0.1172 - val_loss: 3.2107 - val_acc: 0.0615\n",
            "Epoch 119/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.6930 - acc: 0.1180 - val_loss: 3.2082 - val_acc: 0.0615\n",
            "Epoch 120/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.6884 - acc: 0.1193 - val_loss: 3.2201 - val_acc: 0.0630\n",
            "Epoch 121/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.6846 - acc: 0.1193 - val_loss: 3.2229 - val_acc: 0.0628\n",
            "Epoch 122/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.6794 - acc: 0.1203 - val_loss: 3.2328 - val_acc: 0.0638\n",
            "Epoch 123/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.6750 - acc: 0.1212 - val_loss: 3.2245 - val_acc: 0.0625\n",
            "Epoch 124/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.6711 - acc: 0.1220 - val_loss: 3.2331 - val_acc: 0.0633\n",
            "Epoch 125/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.6665 - acc: 0.1228 - val_loss: 3.2286 - val_acc: 0.0638\n",
            "Epoch 126/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.6613 - acc: 0.1242 - val_loss: 3.2347 - val_acc: 0.0635\n",
            "Epoch 127/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.6575 - acc: 0.1244 - val_loss: 3.2487 - val_acc: 0.0618\n",
            "Epoch 128/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.6533 - acc: 0.1249 - val_loss: 3.2485 - val_acc: 0.0625\n",
            "Epoch 129/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.6502 - acc: 0.1260 - val_loss: 3.2436 - val_acc: 0.0628\n",
            "Epoch 130/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.6446 - acc: 0.1268 - val_loss: 3.2625 - val_acc: 0.0618\n",
            "Epoch 131/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.6411 - acc: 0.1277 - val_loss: 3.2461 - val_acc: 0.0633\n",
            "Epoch 132/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.6355 - acc: 0.1286 - val_loss: 3.2639 - val_acc: 0.0633\n",
            "Epoch 133/500\n",
            "2639/2639 [==============================] - 2s 704us/step - loss: 0.6335 - acc: 0.1289 - val_loss: 3.2604 - val_acc: 0.0633\n",
            "Epoch 134/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.6288 - acc: 0.1298 - val_loss: 3.2709 - val_acc: 0.0620\n",
            "Epoch 135/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.6242 - acc: 0.1302 - val_loss: 3.2686 - val_acc: 0.0640\n",
            "Epoch 136/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.6201 - acc: 0.1321 - val_loss: 3.2752 - val_acc: 0.0618\n",
            "Epoch 137/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.6159 - acc: 0.1321 - val_loss: 3.2698 - val_acc: 0.0618\n",
            "Epoch 138/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.6116 - acc: 0.1333 - val_loss: 3.2823 - val_acc: 0.0610\n",
            "Epoch 139/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.6076 - acc: 0.1342 - val_loss: 3.2852 - val_acc: 0.0643\n",
            "Epoch 140/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.6043 - acc: 0.1345 - val_loss: 3.3006 - val_acc: 0.0633\n",
            "Epoch 141/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.5999 - acc: 0.1355 - val_loss: 3.2948 - val_acc: 0.0628\n",
            "Epoch 142/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.5969 - acc: 0.1356 - val_loss: 3.3004 - val_acc: 0.0638\n",
            "Epoch 143/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.5930 - acc: 0.1366 - val_loss: 3.3008 - val_acc: 0.0615\n",
            "Epoch 144/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.5882 - acc: 0.1375 - val_loss: 3.2925 - val_acc: 0.0643\n",
            "Epoch 145/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.5847 - acc: 0.1378 - val_loss: 3.3128 - val_acc: 0.0620\n",
            "Epoch 146/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.5809 - acc: 0.1398 - val_loss: 3.3168 - val_acc: 0.0610\n",
            "Epoch 147/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.5763 - acc: 0.1401 - val_loss: 3.3125 - val_acc: 0.0618\n",
            "Epoch 148/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.5732 - acc: 0.1411 - val_loss: 3.3176 - val_acc: 0.0630\n",
            "Epoch 149/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.5696 - acc: 0.1421 - val_loss: 3.3101 - val_acc: 0.0645\n",
            "Epoch 150/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.5652 - acc: 0.1422 - val_loss: 3.3373 - val_acc: 0.0618\n",
            "Epoch 151/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.5622 - acc: 0.1427 - val_loss: 3.3327 - val_acc: 0.0618\n",
            "Epoch 152/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.5584 - acc: 0.1435 - val_loss: 3.3341 - val_acc: 0.0630\n",
            "Epoch 153/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.5542 - acc: 0.1447 - val_loss: 3.3365 - val_acc: 0.0625\n",
            "Epoch 154/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.5504 - acc: 0.1456 - val_loss: 3.3346 - val_acc: 0.0623\n",
            "Epoch 155/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.5471 - acc: 0.1467 - val_loss: 3.3442 - val_acc: 0.0630\n",
            "Epoch 156/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.5436 - acc: 0.1471 - val_loss: 3.3497 - val_acc: 0.0623\n",
            "Epoch 157/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.5408 - acc: 0.1480 - val_loss: 3.3436 - val_acc: 0.0620\n",
            "Epoch 158/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.5360 - acc: 0.1488 - val_loss: 3.3548 - val_acc: 0.0605\n",
            "Epoch 159/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.5331 - acc: 0.1492 - val_loss: 3.3520 - val_acc: 0.0630\n",
            "Epoch 160/500\n",
            "2639/2639 [==============================] - 2s 692us/step - loss: 0.5289 - acc: 0.1507 - val_loss: 3.3657 - val_acc: 0.0615\n",
            "Epoch 161/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.5265 - acc: 0.1504 - val_loss: 3.3665 - val_acc: 0.0613\n",
            "Epoch 162/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.5221 - acc: 0.1519 - val_loss: 3.3744 - val_acc: 0.0613\n",
            "Epoch 163/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.5185 - acc: 0.1530 - val_loss: 3.3874 - val_acc: 0.0605\n",
            "Epoch 164/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.5163 - acc: 0.1526 - val_loss: 3.3765 - val_acc: 0.0613\n",
            "Epoch 165/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.5113 - acc: 0.1542 - val_loss: 3.3898 - val_acc: 0.0615\n",
            "Epoch 166/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.5095 - acc: 0.1547 - val_loss: 3.3788 - val_acc: 0.0618\n",
            "Epoch 167/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.5059 - acc: 0.1551 - val_loss: 3.3886 - val_acc: 0.0615\n",
            "Epoch 168/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.5022 - acc: 0.1559 - val_loss: 3.3920 - val_acc: 0.0603\n",
            "Epoch 169/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.4984 - acc: 0.1567 - val_loss: 3.3872 - val_acc: 0.0610\n",
            "Epoch 170/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.4955 - acc: 0.1570 - val_loss: 3.4029 - val_acc: 0.0618\n",
            "Epoch 171/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.4921 - acc: 0.1583 - val_loss: 3.4048 - val_acc: 0.0613\n",
            "Epoch 172/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.4892 - acc: 0.1588 - val_loss: 3.4020 - val_acc: 0.0613\n",
            "Epoch 173/500\n",
            "2639/2639 [==============================] - 2s 699us/step - loss: 0.4858 - acc: 0.1595 - val_loss: 3.4122 - val_acc: 0.0610\n",
            "Epoch 174/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.4816 - acc: 0.1604 - val_loss: 3.4097 - val_acc: 0.0600\n",
            "Epoch 175/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.4802 - acc: 0.1604 - val_loss: 3.4267 - val_acc: 0.0620\n",
            "Epoch 176/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.4757 - acc: 0.1611 - val_loss: 3.4114 - val_acc: 0.0615\n",
            "Epoch 177/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.4727 - acc: 0.1618 - val_loss: 3.4189 - val_acc: 0.0628\n",
            "Epoch 178/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.4697 - acc: 0.1629 - val_loss: 3.4261 - val_acc: 0.0620\n",
            "Epoch 179/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.4667 - acc: 0.1633 - val_loss: 3.4293 - val_acc: 0.0635\n",
            "Epoch 180/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.4633 - acc: 0.1639 - val_loss: 3.4369 - val_acc: 0.0633\n",
            "Epoch 181/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.4618 - acc: 0.1648 - val_loss: 3.4487 - val_acc: 0.0623\n",
            "Epoch 182/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.4567 - acc: 0.1659 - val_loss: 3.4405 - val_acc: 0.0618\n",
            "Epoch 183/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.4554 - acc: 0.1656 - val_loss: 3.4398 - val_acc: 0.0605\n",
            "Epoch 184/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.4519 - acc: 0.1669 - val_loss: 3.4407 - val_acc: 0.0623\n",
            "Epoch 185/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.4479 - acc: 0.1672 - val_loss: 3.4450 - val_acc: 0.0610\n",
            "Epoch 186/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.4453 - acc: 0.1681 - val_loss: 3.4519 - val_acc: 0.0618\n",
            "Epoch 187/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.4432 - acc: 0.1682 - val_loss: 3.4604 - val_acc: 0.0608\n",
            "Epoch 188/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.4405 - acc: 0.1691 - val_loss: 3.4647 - val_acc: 0.0615\n",
            "Epoch 189/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.4374 - acc: 0.1697 - val_loss: 3.4716 - val_acc: 0.0633\n",
            "Epoch 190/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.4340 - acc: 0.1698 - val_loss: 3.4641 - val_acc: 0.0618\n",
            "Epoch 191/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.4316 - acc: 0.1707 - val_loss: 3.4773 - val_acc: 0.0613\n",
            "Epoch 192/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.4287 - acc: 0.1714 - val_loss: 3.4863 - val_acc: 0.0618\n",
            "Epoch 193/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.4257 - acc: 0.1722 - val_loss: 3.4768 - val_acc: 0.0610\n",
            "Epoch 194/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.4237 - acc: 0.1724 - val_loss: 3.4823 - val_acc: 0.0608\n",
            "Epoch 195/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.4203 - acc: 0.1733 - val_loss: 3.4874 - val_acc: 0.0618\n",
            "Epoch 196/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.4160 - acc: 0.1741 - val_loss: 3.4982 - val_acc: 0.0625\n",
            "Epoch 197/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.4146 - acc: 0.1737 - val_loss: 3.5032 - val_acc: 0.0603\n",
            "Epoch 198/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.4120 - acc: 0.1749 - val_loss: 3.4967 - val_acc: 0.0603\n",
            "Epoch 199/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.4095 - acc: 0.1756 - val_loss: 3.4994 - val_acc: 0.0615\n",
            "Epoch 200/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.4070 - acc: 0.1753 - val_loss: 3.5084 - val_acc: 0.0613\n",
            "Epoch 201/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.4038 - acc: 0.1767 - val_loss: 3.5091 - val_acc: 0.0608\n",
            "Epoch 202/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.4016 - acc: 0.1767 - val_loss: 3.5191 - val_acc: 0.0608\n",
            "Epoch 203/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.3978 - acc: 0.1777 - val_loss: 3.5168 - val_acc: 0.0615\n",
            "Epoch 204/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.3975 - acc: 0.1780 - val_loss: 3.5144 - val_acc: 0.0615\n",
            "Epoch 205/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.3928 - acc: 0.1786 - val_loss: 3.5210 - val_acc: 0.0610\n",
            "Epoch 206/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.3910 - acc: 0.1794 - val_loss: 3.5328 - val_acc: 0.0608\n",
            "Epoch 207/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.3871 - acc: 0.1800 - val_loss: 3.5296 - val_acc: 0.0618\n",
            "Epoch 208/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.3873 - acc: 0.1800 - val_loss: 3.5456 - val_acc: 0.0618\n",
            "Epoch 209/500\n",
            "2639/2639 [==============================] - 2s 695us/step - loss: 0.3823 - acc: 0.1810 - val_loss: 3.5360 - val_acc: 0.0618\n",
            "Epoch 210/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.3817 - acc: 0.1813 - val_loss: 3.5487 - val_acc: 0.0605\n",
            "Epoch 211/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.3784 - acc: 0.1821 - val_loss: 3.5556 - val_acc: 0.0600\n",
            "Epoch 212/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.3758 - acc: 0.1825 - val_loss: 3.5552 - val_acc: 0.0625\n",
            "Epoch 213/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.3722 - acc: 0.1835 - val_loss: 3.5623 - val_acc: 0.0618\n",
            "Epoch 214/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.3718 - acc: 0.1832 - val_loss: 3.5630 - val_acc: 0.0625\n",
            "Epoch 215/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.3682 - acc: 0.1838 - val_loss: 3.5546 - val_acc: 0.0608\n",
            "Epoch 216/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.3673 - acc: 0.1846 - val_loss: 3.5653 - val_acc: 0.0610\n",
            "Epoch 217/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.3634 - acc: 0.1853 - val_loss: 3.5838 - val_acc: 0.0605\n",
            "Epoch 218/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.3623 - acc: 0.1856 - val_loss: 3.5761 - val_acc: 0.0610\n",
            "Epoch 219/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.3587 - acc: 0.1863 - val_loss: 3.5867 - val_acc: 0.0610\n",
            "Epoch 220/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.3575 - acc: 0.1862 - val_loss: 3.5934 - val_acc: 0.0598\n",
            "Epoch 221/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.3544 - acc: 0.1875 - val_loss: 3.5915 - val_acc: 0.0608\n",
            "Epoch 222/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.3528 - acc: 0.1875 - val_loss: 3.5879 - val_acc: 0.0620\n",
            "Epoch 223/500\n",
            "2639/2639 [==============================] - 2s 719us/step - loss: 0.3495 - acc: 0.1883 - val_loss: 3.5979 - val_acc: 0.0600\n",
            "Epoch 224/500\n",
            "2639/2639 [==============================] - 2s 696us/step - loss: 0.3483 - acc: 0.1884 - val_loss: 3.6131 - val_acc: 0.0600\n",
            "Epoch 225/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.3455 - acc: 0.1888 - val_loss: 3.6109 - val_acc: 0.0618\n",
            "Epoch 226/500\n",
            "2639/2639 [==============================] - 2s 695us/step - loss: 0.3424 - acc: 0.1892 - val_loss: 3.6064 - val_acc: 0.0608\n",
            "Epoch 227/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.3419 - acc: 0.1895 - val_loss: 3.6154 - val_acc: 0.0598\n",
            "Epoch 228/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.3392 - acc: 0.1905 - val_loss: 3.6215 - val_acc: 0.0603\n",
            "Epoch 229/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.3366 - acc: 0.1908 - val_loss: 3.6228 - val_acc: 0.0605\n",
            "Epoch 230/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.3349 - acc: 0.1912 - val_loss: 3.6318 - val_acc: 0.0603\n",
            "Epoch 231/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.3325 - acc: 0.1914 - val_loss: 3.6338 - val_acc: 0.0598\n",
            "Epoch 232/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.3303 - acc: 0.1927 - val_loss: 3.6323 - val_acc: 0.0600\n",
            "Epoch 233/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.3281 - acc: 0.1925 - val_loss: 3.6419 - val_acc: 0.0588\n",
            "Epoch 234/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.3249 - acc: 0.1931 - val_loss: 3.6502 - val_acc: 0.0583\n",
            "Epoch 235/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.3254 - acc: 0.1929 - val_loss: 3.6524 - val_acc: 0.0610\n",
            "Epoch 236/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.3215 - acc: 0.1941 - val_loss: 3.6537 - val_acc: 0.0600\n",
            "Epoch 237/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.3201 - acc: 0.1943 - val_loss: 3.6591 - val_acc: 0.0615\n",
            "Epoch 238/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.3184 - acc: 0.1943 - val_loss: 3.6668 - val_acc: 0.0593\n",
            "Epoch 239/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.3155 - acc: 0.1950 - val_loss: 3.6543 - val_acc: 0.0598\n",
            "Epoch 240/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.3148 - acc: 0.1951 - val_loss: 3.6643 - val_acc: 0.0610\n",
            "Epoch 241/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.3106 - acc: 0.1961 - val_loss: 3.6716 - val_acc: 0.0605\n",
            "Epoch 242/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.3108 - acc: 0.1961 - val_loss: 3.6758 - val_acc: 0.0608\n",
            "Epoch 243/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.3077 - acc: 0.1972 - val_loss: 3.6791 - val_acc: 0.0613\n",
            "Epoch 244/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.3060 - acc: 0.1972 - val_loss: 3.6912 - val_acc: 0.0585\n",
            "Epoch 245/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.3034 - acc: 0.1979 - val_loss: 3.6928 - val_acc: 0.0595\n",
            "Epoch 246/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.3024 - acc: 0.1984 - val_loss: 3.6865 - val_acc: 0.0625\n",
            "Epoch 247/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.3008 - acc: 0.1987 - val_loss: 3.6949 - val_acc: 0.0598\n",
            "Epoch 248/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.2971 - acc: 0.1995 - val_loss: 3.7063 - val_acc: 0.0593\n",
            "Epoch 249/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.2972 - acc: 0.1990 - val_loss: 3.7079 - val_acc: 0.0598\n",
            "Epoch 250/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.2943 - acc: 0.1994 - val_loss: 3.7131 - val_acc: 0.0603\n",
            "Epoch 251/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.2924 - acc: 0.2000 - val_loss: 3.7210 - val_acc: 0.0608\n",
            "Epoch 252/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.2904 - acc: 0.2005 - val_loss: 3.7177 - val_acc: 0.0610\n",
            "Epoch 253/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.2895 - acc: 0.2008 - val_loss: 3.7289 - val_acc: 0.0603\n",
            "Epoch 254/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.2870 - acc: 0.2014 - val_loss: 3.7247 - val_acc: 0.0598\n",
            "Epoch 255/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.2849 - acc: 0.2018 - val_loss: 3.7215 - val_acc: 0.0593\n",
            "Epoch 256/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.2838 - acc: 0.2020 - val_loss: 3.7233 - val_acc: 0.0610\n",
            "Epoch 257/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.2818 - acc: 0.2028 - val_loss: 3.7379 - val_acc: 0.0605\n",
            "Epoch 258/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.2801 - acc: 0.2028 - val_loss: 3.7414 - val_acc: 0.0600\n",
            "Epoch 259/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.2771 - acc: 0.2035 - val_loss: 3.7437 - val_acc: 0.0593\n",
            "Epoch 260/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.2767 - acc: 0.2036 - val_loss: 3.7515 - val_acc: 0.0610\n",
            "Epoch 261/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.2745 - acc: 0.2043 - val_loss: 3.7620 - val_acc: 0.0613\n",
            "Epoch 262/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.2718 - acc: 0.2046 - val_loss: 3.7549 - val_acc: 0.0618\n",
            "Epoch 263/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.2715 - acc: 0.2044 - val_loss: 3.7660 - val_acc: 0.0598\n",
            "Epoch 264/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.2692 - acc: 0.2051 - val_loss: 3.7704 - val_acc: 0.0600\n",
            "Epoch 265/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.2674 - acc: 0.2055 - val_loss: 3.7735 - val_acc: 0.0610\n",
            "Epoch 266/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.2655 - acc: 0.2060 - val_loss: 3.7746 - val_acc: 0.0598\n",
            "Epoch 267/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.2646 - acc: 0.2062 - val_loss: 3.7805 - val_acc: 0.0583\n",
            "Epoch 268/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.2615 - acc: 0.2066 - val_loss: 3.7615 - val_acc: 0.0603\n",
            "Epoch 269/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.2606 - acc: 0.2070 - val_loss: 3.7841 - val_acc: 0.0608\n",
            "Epoch 270/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.2593 - acc: 0.2073 - val_loss: 3.7904 - val_acc: 0.0593\n",
            "Epoch 271/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.2576 - acc: 0.2081 - val_loss: 3.7942 - val_acc: 0.0598\n",
            "Epoch 272/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.2553 - acc: 0.2084 - val_loss: 3.7948 - val_acc: 0.0585\n",
            "Epoch 273/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.2541 - acc: 0.2082 - val_loss: 3.8045 - val_acc: 0.0593\n",
            "Epoch 274/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.2520 - acc: 0.2090 - val_loss: 3.8040 - val_acc: 0.0593\n",
            "Epoch 275/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.2508 - acc: 0.2092 - val_loss: 3.8063 - val_acc: 0.0590\n",
            "Epoch 276/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.2493 - acc: 0.2094 - val_loss: 3.8059 - val_acc: 0.0603\n",
            "Epoch 277/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.2470 - acc: 0.2101 - val_loss: 3.8134 - val_acc: 0.0588\n",
            "Epoch 278/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.2461 - acc: 0.2106 - val_loss: 3.8139 - val_acc: 0.0603\n",
            "Epoch 279/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.2448 - acc: 0.2107 - val_loss: 3.8309 - val_acc: 0.0593\n",
            "Epoch 280/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.2418 - acc: 0.2115 - val_loss: 3.8247 - val_acc: 0.0583\n",
            "Epoch 281/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.2409 - acc: 0.2117 - val_loss: 3.8370 - val_acc: 0.0578\n",
            "Epoch 282/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.2398 - acc: 0.2115 - val_loss: 3.8387 - val_acc: 0.0578\n",
            "Epoch 283/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.2382 - acc: 0.2122 - val_loss: 3.8352 - val_acc: 0.0600\n",
            "Epoch 284/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.2361 - acc: 0.2122 - val_loss: 3.8406 - val_acc: 0.0583\n",
            "Epoch 285/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.2348 - acc: 0.2130 - val_loss: 3.8528 - val_acc: 0.0590\n",
            "Epoch 286/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.2336 - acc: 0.2128 - val_loss: 3.8496 - val_acc: 0.0600\n",
            "Epoch 287/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.2315 - acc: 0.2137 - val_loss: 3.8547 - val_acc: 0.0593\n",
            "Epoch 288/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.2309 - acc: 0.2137 - val_loss: 3.8618 - val_acc: 0.0605\n",
            "Epoch 289/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.2280 - acc: 0.2140 - val_loss: 3.8582 - val_acc: 0.0588\n",
            "Epoch 290/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.2270 - acc: 0.2142 - val_loss: 3.8635 - val_acc: 0.0585\n",
            "Epoch 291/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.2263 - acc: 0.2145 - val_loss: 3.8704 - val_acc: 0.0588\n",
            "Epoch 292/500\n",
            "2639/2639 [==============================] - 2s 709us/step - loss: 0.2234 - acc: 0.2157 - val_loss: 3.8792 - val_acc: 0.0576\n",
            "Epoch 293/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.2243 - acc: 0.2152 - val_loss: 3.8835 - val_acc: 0.0588\n",
            "Epoch 294/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.2216 - acc: 0.2155 - val_loss: 3.8737 - val_acc: 0.0610\n",
            "Epoch 295/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.2202 - acc: 0.2161 - val_loss: 3.8750 - val_acc: 0.0605\n",
            "Epoch 296/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.2192 - acc: 0.2160 - val_loss: 3.8955 - val_acc: 0.0595\n",
            "Epoch 297/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.2166 - acc: 0.2170 - val_loss: 3.8920 - val_acc: 0.0600\n",
            "Epoch 298/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.2165 - acc: 0.2167 - val_loss: 3.8941 - val_acc: 0.0600\n",
            "Epoch 299/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.2144 - acc: 0.2173 - val_loss: 3.8892 - val_acc: 0.0603\n",
            "Epoch 300/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.2143 - acc: 0.2172 - val_loss: 3.8986 - val_acc: 0.0588\n",
            "Epoch 301/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.2119 - acc: 0.2177 - val_loss: 3.9140 - val_acc: 0.0576\n",
            "Epoch 302/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.2100 - acc: 0.2182 - val_loss: 3.9065 - val_acc: 0.0593\n",
            "Epoch 303/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.2093 - acc: 0.2183 - val_loss: 3.9085 - val_acc: 0.0605\n",
            "Epoch 304/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.2078 - acc: 0.2189 - val_loss: 3.9202 - val_acc: 0.0583\n",
            "Epoch 305/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.2068 - acc: 0.2189 - val_loss: 3.9177 - val_acc: 0.0610\n",
            "Epoch 306/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.2047 - acc: 0.2196 - val_loss: 3.9330 - val_acc: 0.0590\n",
            "Epoch 307/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.2034 - acc: 0.2196 - val_loss: 3.9296 - val_acc: 0.0588\n",
            "Epoch 308/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.2023 - acc: 0.2197 - val_loss: 3.9311 - val_acc: 0.0598\n",
            "Epoch 309/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.2022 - acc: 0.2199 - val_loss: 3.9431 - val_acc: 0.0593\n",
            "Epoch 310/500\n",
            "2639/2639 [==============================] - 2s 702us/step - loss: 0.1992 - acc: 0.2206 - val_loss: 3.9477 - val_acc: 0.0578\n",
            "Epoch 311/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.1992 - acc: 0.2210 - val_loss: 3.9424 - val_acc: 0.0568\n",
            "Epoch 312/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.1984 - acc: 0.2205 - val_loss: 3.9475 - val_acc: 0.0583\n",
            "Epoch 313/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.1951 - acc: 0.2219 - val_loss: 3.9546 - val_acc: 0.0578\n",
            "Epoch 314/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.1952 - acc: 0.2216 - val_loss: 3.9575 - val_acc: 0.0581\n",
            "Epoch 315/500\n",
            "2639/2639 [==============================] - 2s 698us/step - loss: 0.1937 - acc: 0.2214 - val_loss: 3.9544 - val_acc: 0.0578\n",
            "Epoch 316/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1920 - acc: 0.2219 - val_loss: 3.9700 - val_acc: 0.0590\n",
            "Epoch 317/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1912 - acc: 0.2222 - val_loss: 3.9618 - val_acc: 0.0578\n",
            "Epoch 318/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1895 - acc: 0.2229 - val_loss: 3.9584 - val_acc: 0.0585\n",
            "Epoch 319/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.1883 - acc: 0.2232 - val_loss: 3.9722 - val_acc: 0.0578\n",
            "Epoch 320/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1876 - acc: 0.2230 - val_loss: 3.9751 - val_acc: 0.0573\n",
            "Epoch 321/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.1861 - acc: 0.2233 - val_loss: 3.9820 - val_acc: 0.0578\n",
            "Epoch 322/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.1848 - acc: 0.2238 - val_loss: 3.9779 - val_acc: 0.0576\n",
            "Epoch 323/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.1830 - acc: 0.2240 - val_loss: 3.9848 - val_acc: 0.0576\n",
            "Epoch 324/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.1824 - acc: 0.2246 - val_loss: 4.0049 - val_acc: 0.0563\n",
            "Epoch 325/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.1817 - acc: 0.2246 - val_loss: 4.0005 - val_acc: 0.0576\n",
            "Epoch 326/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.1806 - acc: 0.2243 - val_loss: 4.0026 - val_acc: 0.0571\n",
            "Epoch 327/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.1786 - acc: 0.2253 - val_loss: 4.0208 - val_acc: 0.0568\n",
            "Epoch 328/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1777 - acc: 0.2254 - val_loss: 3.9995 - val_acc: 0.0568\n",
            "Epoch 329/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.1756 - acc: 0.2254 - val_loss: 4.0087 - val_acc: 0.0571\n",
            "Epoch 330/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1755 - acc: 0.2258 - val_loss: 4.0088 - val_acc: 0.0576\n",
            "Epoch 331/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.1742 - acc: 0.2260 - val_loss: 4.0213 - val_acc: 0.0578\n",
            "Epoch 332/500\n",
            "2639/2639 [==============================] - 2s 671us/step - loss: 0.1730 - acc: 0.2264 - val_loss: 4.0215 - val_acc: 0.0578\n",
            "Epoch 333/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1714 - acc: 0.2270 - val_loss: 4.0228 - val_acc: 0.0566\n",
            "Epoch 334/500\n",
            "2639/2639 [==============================] - 2s 692us/step - loss: 0.1706 - acc: 0.2269 - val_loss: 4.0201 - val_acc: 0.0568\n",
            "Epoch 335/500\n",
            "2639/2639 [==============================] - 2s 699us/step - loss: 0.1696 - acc: 0.2270 - val_loss: 4.0336 - val_acc: 0.0553\n",
            "Epoch 336/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.1688 - acc: 0.2274 - val_loss: 4.0316 - val_acc: 0.0561\n",
            "Epoch 337/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.1670 - acc: 0.2282 - val_loss: 4.0328 - val_acc: 0.0558\n",
            "Epoch 338/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.1664 - acc: 0.2282 - val_loss: 4.0578 - val_acc: 0.0543\n",
            "Epoch 339/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.1651 - acc: 0.2284 - val_loss: 4.0446 - val_acc: 0.0571\n",
            "Epoch 340/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.1636 - acc: 0.2287 - val_loss: 4.0555 - val_acc: 0.0568\n",
            "Epoch 341/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.1627 - acc: 0.2288 - val_loss: 4.0601 - val_acc: 0.0573\n",
            "Epoch 342/500\n",
            "2639/2639 [==============================] - 2s 696us/step - loss: 0.1616 - acc: 0.2291 - val_loss: 4.0584 - val_acc: 0.0553\n",
            "Epoch 343/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.1608 - acc: 0.2294 - val_loss: 4.0525 - val_acc: 0.0551\n",
            "Epoch 344/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.1598 - acc: 0.2295 - val_loss: 4.0778 - val_acc: 0.0548\n",
            "Epoch 345/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.1593 - acc: 0.2291 - val_loss: 4.0690 - val_acc: 0.0566\n",
            "Epoch 346/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.1577 - acc: 0.2298 - val_loss: 4.0853 - val_acc: 0.0563\n",
            "Epoch 347/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.1557 - acc: 0.2304 - val_loss: 4.0793 - val_acc: 0.0561\n",
            "Epoch 348/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.1561 - acc: 0.2304 - val_loss: 4.0795 - val_acc: 0.0573\n",
            "Epoch 349/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.1542 - acc: 0.2308 - val_loss: 4.0937 - val_acc: 0.0566\n",
            "Epoch 350/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.1535 - acc: 0.2311 - val_loss: 4.0888 - val_acc: 0.0566\n",
            "Epoch 351/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.1520 - acc: 0.2311 - val_loss: 4.0950 - val_acc: 0.0561\n",
            "Epoch 352/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1516 - acc: 0.2314 - val_loss: 4.0970 - val_acc: 0.0568\n",
            "Epoch 353/500\n",
            "2639/2639 [==============================] - 2s 705us/step - loss: 0.1506 - acc: 0.2316 - val_loss: 4.1009 - val_acc: 0.0573\n",
            "Epoch 354/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.1487 - acc: 0.2321 - val_loss: 4.0959 - val_acc: 0.0573\n",
            "Epoch 355/500\n",
            "2639/2639 [==============================] - 2s 696us/step - loss: 0.1494 - acc: 0.2318 - val_loss: 4.1087 - val_acc: 0.0553\n",
            "Epoch 356/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.1472 - acc: 0.2325 - val_loss: 4.1126 - val_acc: 0.0558\n",
            "Epoch 357/500\n",
            "2639/2639 [==============================] - 2s 697us/step - loss: 0.1467 - acc: 0.2326 - val_loss: 4.1201 - val_acc: 0.0573\n",
            "Epoch 358/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.1451 - acc: 0.2331 - val_loss: 4.1239 - val_acc: 0.0548\n",
            "Epoch 359/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1443 - acc: 0.2331 - val_loss: 4.1269 - val_acc: 0.0548\n",
            "Epoch 360/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1439 - acc: 0.2330 - val_loss: 4.1159 - val_acc: 0.0573\n",
            "Epoch 361/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.1415 - acc: 0.2339 - val_loss: 4.1396 - val_acc: 0.0581\n",
            "Epoch 362/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1422 - acc: 0.2335 - val_loss: 4.1391 - val_acc: 0.0566\n",
            "Epoch 363/500\n",
            "2639/2639 [==============================] - 2s 668us/step - loss: 0.1406 - acc: 0.2342 - val_loss: 4.1394 - val_acc: 0.0566\n",
            "Epoch 364/500\n",
            "2639/2639 [==============================] - 2s 699us/step - loss: 0.1395 - acc: 0.2344 - val_loss: 4.1499 - val_acc: 0.0556\n",
            "Epoch 365/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1399 - acc: 0.2338 - val_loss: 4.1523 - val_acc: 0.0568\n",
            "Epoch 366/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.1375 - acc: 0.2349 - val_loss: 4.1454 - val_acc: 0.0576\n",
            "Epoch 367/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.1363 - acc: 0.2351 - val_loss: 4.1527 - val_acc: 0.0533\n",
            "Epoch 368/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.1355 - acc: 0.2355 - val_loss: 4.1728 - val_acc: 0.0536\n",
            "Epoch 369/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.1356 - acc: 0.2353 - val_loss: 4.1599 - val_acc: 0.0566\n",
            "Epoch 370/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.1338 - acc: 0.2358 - val_loss: 4.1666 - val_acc: 0.0553\n",
            "Epoch 371/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1325 - acc: 0.2361 - val_loss: 4.1755 - val_acc: 0.0556\n",
            "Epoch 372/500\n",
            "2639/2639 [==============================] - 2s 671us/step - loss: 0.1330 - acc: 0.2357 - val_loss: 4.1727 - val_acc: 0.0553\n",
            "Epoch 373/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1305 - acc: 0.2364 - val_loss: 4.1912 - val_acc: 0.0556\n",
            "Epoch 374/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.1306 - acc: 0.2365 - val_loss: 4.1746 - val_acc: 0.0551\n",
            "Epoch 375/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1307 - acc: 0.2365 - val_loss: 4.1747 - val_acc: 0.0546\n",
            "Epoch 376/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.1286 - acc: 0.2370 - val_loss: 4.1758 - val_acc: 0.0568\n",
            "Epoch 377/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.1277 - acc: 0.2376 - val_loss: 4.1967 - val_acc: 0.0561\n",
            "Epoch 378/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.1267 - acc: 0.2376 - val_loss: 4.1917 - val_acc: 0.0563\n",
            "Epoch 379/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.1270 - acc: 0.2374 - val_loss: 4.1952 - val_acc: 0.0556\n",
            "Epoch 380/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1251 - acc: 0.2382 - val_loss: 4.2088 - val_acc: 0.0568\n",
            "Epoch 381/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.1244 - acc: 0.2382 - val_loss: 4.2032 - val_acc: 0.0548\n",
            "Epoch 382/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.1239 - acc: 0.2382 - val_loss: 4.2099 - val_acc: 0.0558\n",
            "Epoch 383/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.1217 - acc: 0.2389 - val_loss: 4.2021 - val_acc: 0.0571\n",
            "Epoch 384/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1218 - acc: 0.2387 - val_loss: 4.2099 - val_acc: 0.0553\n",
            "Epoch 385/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.1213 - acc: 0.2390 - val_loss: 4.2121 - val_acc: 0.0558\n",
            "Epoch 386/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.1198 - acc: 0.2391 - val_loss: 4.2221 - val_acc: 0.0561\n",
            "Epoch 387/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.1190 - acc: 0.2393 - val_loss: 4.2172 - val_acc: 0.0551\n",
            "Epoch 388/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.1186 - acc: 0.2396 - val_loss: 4.2179 - val_acc: 0.0556\n",
            "Epoch 389/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1173 - acc: 0.2395 - val_loss: 4.2439 - val_acc: 0.0536\n",
            "Epoch 390/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.1167 - acc: 0.2399 - val_loss: 4.2234 - val_acc: 0.0541\n",
            "Epoch 391/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.1160 - acc: 0.2399 - val_loss: 4.2352 - val_acc: 0.0553\n",
            "Epoch 392/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.1148 - acc: 0.2404 - val_loss: 4.2365 - val_acc: 0.0563\n",
            "Epoch 393/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1146 - acc: 0.2397 - val_loss: 4.2328 - val_acc: 0.0538\n",
            "Epoch 394/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.1145 - acc: 0.2403 - val_loss: 4.2407 - val_acc: 0.0568\n",
            "Epoch 395/500\n",
            "2639/2639 [==============================] - 2s 722us/step - loss: 0.1133 - acc: 0.2406 - val_loss: 4.2431 - val_acc: 0.0571\n",
            "Epoch 396/500\n",
            "2639/2639 [==============================] - 2s 693us/step - loss: 0.1121 - acc: 0.2410 - val_loss: 4.2589 - val_acc: 0.0553\n",
            "Epoch 397/500\n",
            "2639/2639 [==============================] - 2s 690us/step - loss: 0.1114 - acc: 0.2410 - val_loss: 4.2534 - val_acc: 0.0556\n",
            "Epoch 398/500\n",
            "2639/2639 [==============================] - 2s 706us/step - loss: 0.1111 - acc: 0.2409 - val_loss: 4.2594 - val_acc: 0.0541\n",
            "Epoch 399/500\n",
            "2639/2639 [==============================] - 2s 692us/step - loss: 0.1097 - acc: 0.2413 - val_loss: 4.2593 - val_acc: 0.0568\n",
            "Epoch 400/500\n",
            "2639/2639 [==============================] - 2s 698us/step - loss: 0.1091 - acc: 0.2414 - val_loss: 4.2512 - val_acc: 0.0556\n",
            "Epoch 401/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.1081 - acc: 0.2416 - val_loss: 4.2656 - val_acc: 0.0548\n",
            "Epoch 402/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.1082 - acc: 0.2416 - val_loss: 4.2677 - val_acc: 0.0551\n",
            "Epoch 403/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1068 - acc: 0.2419 - val_loss: 4.2901 - val_acc: 0.0541\n",
            "Epoch 404/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.1070 - acc: 0.2415 - val_loss: 4.2758 - val_acc: 0.0556\n",
            "Epoch 405/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.1061 - acc: 0.2418 - val_loss: 4.2626 - val_acc: 0.0558\n",
            "Epoch 406/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.1042 - acc: 0.2425 - val_loss: 4.2661 - val_acc: 0.0576\n",
            "Epoch 407/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1044 - acc: 0.2423 - val_loss: 4.2792 - val_acc: 0.0566\n",
            "Epoch 408/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.1035 - acc: 0.2425 - val_loss: 4.3038 - val_acc: 0.0558\n",
            "Epoch 409/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.1016 - acc: 0.2431 - val_loss: 4.2834 - val_acc: 0.0563\n",
            "Epoch 410/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.1025 - acc: 0.2427 - val_loss: 4.2913 - val_acc: 0.0568\n",
            "Epoch 411/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.1009 - acc: 0.2431 - val_loss: 4.2995 - val_acc: 0.0566\n",
            "Epoch 412/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.1003 - acc: 0.2431 - val_loss: 4.3102 - val_acc: 0.0566\n",
            "Epoch 413/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.0998 - acc: 0.2431 - val_loss: 4.3120 - val_acc: 0.0556\n",
            "Epoch 414/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.0991 - acc: 0.2432 - val_loss: 4.3052 - val_acc: 0.0561\n",
            "Epoch 415/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.0973 - acc: 0.2440 - val_loss: 4.3205 - val_acc: 0.0556\n",
            "Epoch 416/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.0982 - acc: 0.2434 - val_loss: 4.3202 - val_acc: 0.0548\n",
            "Epoch 417/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0965 - acc: 0.2442 - val_loss: 4.3137 - val_acc: 0.0563\n",
            "Epoch 418/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0965 - acc: 0.2437 - val_loss: 4.3272 - val_acc: 0.0541\n",
            "Epoch 419/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.0957 - acc: 0.2441 - val_loss: 4.3290 - val_acc: 0.0571\n",
            "Epoch 420/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.0954 - acc: 0.2440 - val_loss: 4.3420 - val_acc: 0.0561\n",
            "Epoch 421/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0933 - acc: 0.2448 - val_loss: 4.3426 - val_acc: 0.0568\n",
            "Epoch 422/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.0936 - acc: 0.2444 - val_loss: 4.3444 - val_acc: 0.0561\n",
            "Epoch 423/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0933 - acc: 0.2445 - val_loss: 4.3478 - val_acc: 0.0568\n",
            "Epoch 424/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0920 - acc: 0.2447 - val_loss: 4.3506 - val_acc: 0.0556\n",
            "Epoch 425/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.0916 - acc: 0.2449 - val_loss: 4.3575 - val_acc: 0.0563\n",
            "Epoch 426/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0905 - acc: 0.2455 - val_loss: 4.3549 - val_acc: 0.0556\n",
            "Epoch 427/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0916 - acc: 0.2451 - val_loss: 4.3468 - val_acc: 0.0551\n",
            "Epoch 428/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.0892 - acc: 0.2455 - val_loss: 4.3431 - val_acc: 0.0578\n",
            "Epoch 429/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.0890 - acc: 0.2454 - val_loss: 4.3635 - val_acc: 0.0561\n",
            "Epoch 430/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0888 - acc: 0.2455 - val_loss: 4.3787 - val_acc: 0.0568\n",
            "Epoch 431/500\n",
            "2639/2639 [==============================] - 2s 691us/step - loss: 0.0876 - acc: 0.2455 - val_loss: 4.3681 - val_acc: 0.0561\n",
            "Epoch 432/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.0869 - acc: 0.2458 - val_loss: 4.3625 - val_acc: 0.0588\n",
            "Epoch 433/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.0871 - acc: 0.2457 - val_loss: 4.3719 - val_acc: 0.0571\n",
            "Epoch 434/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.0855 - acc: 0.2462 - val_loss: 4.3754 - val_acc: 0.0551\n",
            "Epoch 435/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.0856 - acc: 0.2461 - val_loss: 4.3871 - val_acc: 0.0553\n",
            "Epoch 436/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0841 - acc: 0.2463 - val_loss: 4.3745 - val_acc: 0.0556\n",
            "Epoch 437/500\n",
            "2639/2639 [==============================] - 2s 670us/step - loss: 0.0845 - acc: 0.2463 - val_loss: 4.3801 - val_acc: 0.0548\n",
            "Epoch 438/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.0840 - acc: 0.2464 - val_loss: 4.3941 - val_acc: 0.0553\n",
            "Epoch 439/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.0834 - acc: 0.2466 - val_loss: 4.3944 - val_acc: 0.0571\n",
            "Epoch 440/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.0828 - acc: 0.2466 - val_loss: 4.3983 - val_acc: 0.0561\n",
            "Epoch 441/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0809 - acc: 0.2471 - val_loss: 4.4110 - val_acc: 0.0561\n",
            "Epoch 442/500\n",
            "2639/2639 [==============================] - 2s 701us/step - loss: 0.0819 - acc: 0.2468 - val_loss: 4.3889 - val_acc: 0.0558\n",
            "Epoch 443/500\n",
            "2639/2639 [==============================] - 2s 671us/step - loss: 0.0805 - acc: 0.2471 - val_loss: 4.4025 - val_acc: 0.0578\n",
            "Epoch 444/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.0811 - acc: 0.2470 - val_loss: 4.3998 - val_acc: 0.0556\n",
            "Epoch 445/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.0791 - acc: 0.2471 - val_loss: 4.4112 - val_acc: 0.0571\n",
            "Epoch 446/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.0790 - acc: 0.2474 - val_loss: 4.4007 - val_acc: 0.0581\n",
            "Epoch 447/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0790 - acc: 0.2474 - val_loss: 4.4213 - val_acc: 0.0563\n",
            "Epoch 448/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0783 - acc: 0.2475 - val_loss: 4.4244 - val_acc: 0.0563\n",
            "Epoch 449/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.0769 - acc: 0.2479 - val_loss: 4.4164 - val_acc: 0.0576\n",
            "Epoch 450/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.0772 - acc: 0.2478 - val_loss: 4.4229 - val_acc: 0.0566\n",
            "Epoch 451/500\n",
            "2639/2639 [==============================] - 2s 692us/step - loss: 0.0751 - acc: 0.2483 - val_loss: 4.4372 - val_acc: 0.0568\n",
            "Epoch 452/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.0768 - acc: 0.2478 - val_loss: 4.4343 - val_acc: 0.0576\n",
            "Epoch 453/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.0751 - acc: 0.2480 - val_loss: 4.4369 - val_acc: 0.0568\n",
            "Epoch 454/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.0748 - acc: 0.2482 - val_loss: 4.4308 - val_acc: 0.0568\n",
            "Epoch 455/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0747 - acc: 0.2483 - val_loss: 4.4374 - val_acc: 0.0546\n",
            "Epoch 456/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0730 - acc: 0.2487 - val_loss: 4.4409 - val_acc: 0.0568\n",
            "Epoch 457/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.0744 - acc: 0.2484 - val_loss: 4.4344 - val_acc: 0.0578\n",
            "Epoch 458/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0720 - acc: 0.2488 - val_loss: 4.4448 - val_acc: 0.0561\n",
            "Epoch 459/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.0728 - acc: 0.2491 - val_loss: 4.4498 - val_acc: 0.0566\n",
            "Epoch 460/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.0721 - acc: 0.2489 - val_loss: 4.4503 - val_acc: 0.0573\n",
            "Epoch 461/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0704 - acc: 0.2492 - val_loss: 4.4438 - val_acc: 0.0571\n",
            "Epoch 462/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.0708 - acc: 0.2493 - val_loss: 4.4693 - val_acc: 0.0578\n",
            "Epoch 463/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.0710 - acc: 0.2490 - val_loss: 4.4699 - val_acc: 0.0583\n",
            "Epoch 464/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.0692 - acc: 0.2495 - val_loss: 4.4722 - val_acc: 0.0566\n",
            "Epoch 465/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0692 - acc: 0.2494 - val_loss: 4.4719 - val_acc: 0.0553\n",
            "Epoch 466/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0679 - acc: 0.2496 - val_loss: 4.4728 - val_acc: 0.0568\n",
            "Epoch 467/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.0686 - acc: 0.2494 - val_loss: 4.4780 - val_acc: 0.0566\n",
            "Epoch 468/500\n",
            "2639/2639 [==============================] - 2s 681us/step - loss: 0.0681 - acc: 0.2496 - val_loss: 4.4847 - val_acc: 0.0561\n",
            "Epoch 469/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0680 - acc: 0.2495 - val_loss: 4.4850 - val_acc: 0.0578\n",
            "Epoch 470/500\n",
            "2639/2639 [==============================] - 2s 694us/step - loss: 0.0671 - acc: 0.2495 - val_loss: 4.4830 - val_acc: 0.0568\n",
            "Epoch 471/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.0668 - acc: 0.2496 - val_loss: 4.4874 - val_acc: 0.0556\n",
            "Epoch 472/500\n",
            "2639/2639 [==============================] - 2s 680us/step - loss: 0.0651 - acc: 0.2500 - val_loss: 4.4906 - val_acc: 0.0566\n",
            "Epoch 473/500\n",
            "2639/2639 [==============================] - 2s 677us/step - loss: 0.0645 - acc: 0.2501 - val_loss: 4.4929 - val_acc: 0.0558\n",
            "Epoch 474/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0651 - acc: 0.2503 - val_loss: 4.4996 - val_acc: 0.0563\n",
            "Epoch 475/500\n",
            "2639/2639 [==============================] - 2s 683us/step - loss: 0.0644 - acc: 0.2502 - val_loss: 4.5084 - val_acc: 0.0573\n",
            "Epoch 476/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0650 - acc: 0.2498 - val_loss: 4.5033 - val_acc: 0.0553\n",
            "Epoch 477/500\n",
            "2639/2639 [==============================] - 2s 675us/step - loss: 0.0630 - acc: 0.2505 - val_loss: 4.5115 - val_acc: 0.0581\n",
            "Epoch 478/500\n",
            "2639/2639 [==============================] - 2s 678us/step - loss: 0.0637 - acc: 0.2504 - val_loss: 4.5129 - val_acc: 0.0556\n",
            "Epoch 479/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.0622 - acc: 0.2507 - val_loss: 4.5143 - val_acc: 0.0563\n",
            "Epoch 480/500\n",
            "2639/2639 [==============================] - 2s 672us/step - loss: 0.0625 - acc: 0.2507 - val_loss: 4.5193 - val_acc: 0.0556\n",
            "Epoch 481/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0623 - acc: 0.2509 - val_loss: 4.5130 - val_acc: 0.0563\n",
            "Epoch 482/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.0615 - acc: 0.2509 - val_loss: 4.5101 - val_acc: 0.0546\n",
            "Epoch 483/500\n",
            "2639/2639 [==============================] - 2s 674us/step - loss: 0.0604 - acc: 0.2508 - val_loss: 4.5316 - val_acc: 0.0561\n",
            "Epoch 484/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0606 - acc: 0.2510 - val_loss: 4.5314 - val_acc: 0.0558\n",
            "Epoch 485/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0602 - acc: 0.2510 - val_loss: 4.5236 - val_acc: 0.0563\n",
            "Epoch 486/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0596 - acc: 0.2511 - val_loss: 4.5370 - val_acc: 0.0561\n",
            "Epoch 487/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.0599 - acc: 0.2512 - val_loss: 4.5300 - val_acc: 0.0568\n",
            "Epoch 488/500\n",
            "2639/2639 [==============================] - 2s 687us/step - loss: 0.0588 - acc: 0.2512 - val_loss: 4.5354 - val_acc: 0.0558\n",
            "Epoch 489/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.0579 - acc: 0.2512 - val_loss: 4.5405 - val_acc: 0.0561\n",
            "Epoch 490/500\n",
            "2639/2639 [==============================] - 2s 689us/step - loss: 0.0582 - acc: 0.2513 - val_loss: 4.5453 - val_acc: 0.0548\n",
            "Epoch 491/500\n",
            "2639/2639 [==============================] - 2s 684us/step - loss: 0.0581 - acc: 0.2514 - val_loss: 4.5439 - val_acc: 0.0571\n",
            "Epoch 492/500\n",
            "2639/2639 [==============================] - 2s 673us/step - loss: 0.0574 - acc: 0.2515 - val_loss: 4.5396 - val_acc: 0.0566\n",
            "Epoch 493/500\n",
            "2639/2639 [==============================] - 2s 676us/step - loss: 0.0558 - acc: 0.2520 - val_loss: 4.5487 - val_acc: 0.0576\n",
            "Epoch 494/500\n",
            "2639/2639 [==============================] - 2s 688us/step - loss: 0.0570 - acc: 0.2515 - val_loss: 4.5499 - val_acc: 0.0571\n",
            "Epoch 495/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.0563 - acc: 0.2518 - val_loss: 4.5538 - val_acc: 0.0573\n",
            "Epoch 496/500\n",
            "2639/2639 [==============================] - 2s 679us/step - loss: 0.0558 - acc: 0.2518 - val_loss: 4.5531 - val_acc: 0.0563\n",
            "Epoch 497/500\n",
            "2639/2639 [==============================] - 2s 685us/step - loss: 0.0548 - acc: 0.2521 - val_loss: 4.5620 - val_acc: 0.0583\n",
            "Epoch 498/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0548 - acc: 0.2520 - val_loss: 4.5459 - val_acc: 0.0566\n",
            "Epoch 499/500\n",
            "2639/2639 [==============================] - 2s 686us/step - loss: 0.0538 - acc: 0.2523 - val_loss: 4.5670 - val_acc: 0.0551\n",
            "Epoch 500/500\n",
            "2639/2639 [==============================] - 2s 682us/step - loss: 0.0537 - acc: 0.2526 - val_loss: 4.5694 - val_acc: 0.0558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15a7b95940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PySr0wADfYdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uEcYN2vfYdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create sampling model\n",
        "decoder_state_input_h = Input(shape=(50,))\n",
        "decoder_state_input_c = Input(shape=(50,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "final_dex2= dex(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WScBcrv3fYdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to generate sequences\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 52):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T403CdlmfYdQ",
        "colab_type": "code",
        "outputId": "da9274b8-9c3b-43e0-c77c-e22ffe6f9085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6817
        }
      },
      "source": [
        "#Look at some translations\n",
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', lines.eng[seq_index: seq_index + 1])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: 0    wow\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  वाह _END\n",
            "-\n",
            "Input sentence: 1    help\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  कुरसियाँ काफ़ी हैं क्या _END\n",
            "-\n",
            "Input sentence: 2    jump\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  कूदो _END\n",
            "-\n",
            "Input sentence: 3    jump\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  कूदो _END\n",
            "-\n",
            "Input sentence: 4    jump\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  कूदो _END\n",
            "-\n",
            "Input sentence: 5    hello\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  नमस्कार। _END\n",
            "-\n",
            "Input sentence: 6    hello\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  नमस्कार। _END\n",
            "-\n",
            "Input sentence: 7    cheers\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  वाहवाह _END\n",
            "-\n",
            "Input sentence: 8    cheers\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  वाहवाह _END\n",
            "-\n",
            "Input sentence: 9    got it\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  समझे कि नहीं _END\n",
            "-\n",
            "Input sentence: 10    im ok\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं ठीक हूँ। _END\n",
            "-\n",
            "Input sentence: 11    awesome\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  बहुत बढ़िया _END\n",
            "-\n",
            "Input sentence: 12    come in\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  अंदर आ जाओ। _END\n",
            "-\n",
            "Input sentence: 13    get out\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  बाहर निकल जाओ _END\n",
            "-\n",
            "Input sentence: 14    go away\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मोटे मत हो जाना। _END\n",
            "-\n",
            "Input sentence: 15    goodbye\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  रेखांकित शब्दों को सुधारिए। _END\n",
            "-\n",
            "Input sentence: 16    perfect\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  सही _END\n",
            "-\n",
            "Input sentence: 17    perfect\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  सही _END\n",
            "-\n",
            "Input sentence: 18    welcome\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आपका स्वागत है। _END\n",
            "-\n",
            "Input sentence: 19    welcome\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आपका स्वागत है। _END\n",
            "-\n",
            "Input sentence: 20    have fun\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मज़े करो। _END\n",
            "-\n",
            "Input sentence: 21    have fun\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मज़े करो। _END\n",
            "-\n",
            "Input sentence: 22    have fun\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मज़े करो। _END\n",
            "-\n",
            "Input sentence: 23    i forgot\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं भूल गई। _END\n",
            "-\n",
            "Input sentence: 24    i forgot\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं भूल गई। _END\n",
            "-\n",
            "Input sentence: 25    ill pay\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं पैसे दूंगा। _END\n",
            "-\n",
            "Input sentence: 26    im fine\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं ठीक हूँ। _END\n",
            "-\n",
            "Input sentence: 27    im full\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मेरा पेट भर गया है। _END\n",
            "-\n",
            "Input sentence: 28    lets go\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  चलो चलें _END\n",
            "-\n",
            "Input sentence: 29    answer me\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे जवाब दो। _END\n",
            "-\n",
            "Input sentence: 30    birds fly\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  पंछी उड़ते हैं। _END\n",
            "-\n",
            "Input sentence: 31    excuse me\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  माफ़ कीजिए। _END\n",
            "-\n",
            "Input sentence: 32    fantastic\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  बहुत ख़ूब _END\n",
            "-\n",
            "Input sentence: 33    i fainted\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं बेहोश हो गया। _END\n",
            "-\n",
            "Input sentence: 34    i fear so\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  खेद की बात है COMMA लेकिन वैसा ही है। _END\n",
            "-\n",
            "Input sentence: 35    i laughed\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं हँसा। _END\n",
            "-\n",
            "Input sentence: 36    im bored\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं बोर हो रहा हूँ। _END\n",
            "-\n",
            "Input sentence: 37    im broke\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मेरा दीवालिया हो चुका है। _END\n",
            "-\n",
            "Input sentence: 38    im tired\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं थक गया हूँ। _END\n",
            "-\n",
            "Input sentence: 39    its cold\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  ठंड हो रही है। _END\n",
            "-\n",
            "Input sentence: 40    well done\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  शाबाश _END\n",
            "-\n",
            "Input sentence: 41    who knows\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  किसे पता है _END\n",
            "-\n",
            "Input sentence: 42    who knows\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  किसे पता है _END\n",
            "-\n",
            "Input sentence: 43    who knows\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  किसे पता है _END\n",
            "-\n",
            "Input sentence: 44    who knows\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  किसे पता है _END\n",
            "-\n",
            "Input sentence: 45    wonderful\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  अद्भुत _END\n",
            "-\n",
            "Input sentence: 46    birds sing\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  पंछी गाते हैं। _END\n",
            "-\n",
            "Input sentence: 47    come on in\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  अंदर आ जाओ। _END\n",
            "-\n",
            "Input sentence: 48    definitely\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  निश्चित ही _END\n",
            "-\n",
            "Input sentence: 49    dont move\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मज़े करो। _END\n",
            "-\n",
            "Input sentence: 50    fire burns\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आग जलाती है। _END\n",
            "-\n",
            "Input sentence: 51    follow him\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  उसका पीछा करो। _END\n",
            "-\n",
            "Input sentence: 52    i can swim\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तैर सकता हूँ। _END\n",
            "-\n",
            "Input sentence: 53    i can swim\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तैर सकता हूँ। _END\n",
            "-\n",
            "Input sentence: 54    i love you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तुमसे प्यार करती हूँ। _END\n",
            "-\n",
            "Input sentence: 55    i love you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तुमसे प्यार करती हूँ। _END\n",
            "-\n",
            "Input sentence: 56    i love you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तुमसे प्यार करती हूँ। _END\n",
            "-\n",
            "Input sentence: 57    i love you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तुमसे प्यार करती हूँ। _END\n",
            "-\n",
            "Input sentence: 58    i love you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं तुमसे प्यार करती हूँ। _END\n",
            "-\n",
            "Input sentence: 59    i will try\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं कोशिश करूँगा। _END\n",
            "-\n",
            "Input sentence: 60    im coming\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं आ रहा हूँ। _END\n",
            "-\n",
            "Input sentence: 61    im hungry\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे कुत्ते अच्छे लगते हैं। _END\n",
            "-\n",
            "Input sentence: 62    im hungry\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे कुत्ते अच्छे लगते हैं। _END\n",
            "-\n",
            "Input sentence: 63    let him in\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  उसे अंगर आने दो। _END\n",
            "-\n",
            "Input sentence: 64    let him in\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  उसे अंगर आने दो। _END\n",
            "-\n",
            "Input sentence: 65    let me out\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे बाहर जाने नहीं था। _END\n",
            "-\n",
            "Input sentence: 66    once again\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  और एक बार। _END\n",
            "-\n",
            "Input sentence: 67    please sit\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  बैठिए। _END\n",
            "-\n",
            "Input sentence: 68    that a boy\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  शाबाश _END\n",
            "-\n",
            "Input sentence: 69    whats new\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  क्या नया है _END\n",
            "-\n",
            "Input sentence: 70    whats new\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  क्या नया है _END\n",
            "-\n",
            "Input sentence: 71    whos that\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  वह कौन है _END\n",
            "-\n",
            "Input sentence: 72    dont shout\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  चिल्लाईए मत। _END\n",
            "-\n",
            "Input sentence: 73    dont shout\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  चिल्लाईए मत। _END\n",
            "-\n",
            "Input sentence: 74    he stood up\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  वह खड़ा हो गया। _END\n",
            "-\n",
            "Input sentence: 75    hes strong\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  वह ताकतवर है। _END\n",
            "-\n",
            "Input sentence: 76    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 77    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 78    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 79    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 80    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 81    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 82    how are you\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  आप कैसे हो _END\n",
            "-\n",
            "Input sentence: 83    i like both\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे दोनो पसंद हैं। _END\n",
            "-\n",
            "Input sentence: 84    i like cake\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे केक अच्छा लगता है। _END\n",
            "-\n",
            "Input sentence: 85    i like dogs\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे कुत्ते अच्छे लगते हैं। _END\n",
            "-\n",
            "Input sentence: 86    i like math\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे गणित पसंद है। _END\n",
            "-\n",
            "Input sentence: 87    ill attend\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं आऊंगा। _END\n",
            "-\n",
            "Input sentence: 88    nobody came\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  कोई नहीं आया। _END\n",
            "-\n",
            "Input sentence: 89    was i wrong\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  क्या मैं ग़लत था _END\n",
            "-\n",
            "Input sentence: 90    whats this\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  यह क्या है _END\n",
            "-\n",
            "Input sentence: 91    are you sick\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  क्या तुम बीमार हो _END\n",
            "-\n",
            "Input sentence: 92    bring him in\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  उसको अंदर ले आओ। _END\n",
            "-\n",
            "Input sentence: 93    come with us\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  हमारे साथ आओ। _END\n",
            "-\n",
            "Input sentence: 94    happy easter\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  एसटर मुबारक हो _END\n",
            "-\n",
            "Input sentence: 95    has tom left\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  टॉम चला गया क्या _END\n",
            "-\n",
            "Input sentence: 96    i am at home\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं घर पर हूँ। _END\n",
            "-\n",
            "Input sentence: 97    i cant move\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मैं हिल नहीं सकता। _END\n",
            "-\n",
            "Input sentence: 98    i dont know\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे नहीं मालूम। _END\n",
            "-\n",
            "Input sentence: 99    i dont know\n",
            "Name: eng, dtype: object\n",
            "Decoded sentence:  मुझे नहीं मालूम। _END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoZXGFkChtG7",
        "colab_type": "text"
      },
      "source": [
        "#Summary:\n",
        "### From the above, we can say that most of the sentences are being translated correctly."
      ]
    }
  ]
}